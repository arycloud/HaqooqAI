{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-29T06:24:25.013800Z",
     "start_time": "2025-07-29T06:24:12.357066Z"
    }
   },
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm.notebook import tqdm\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T06:25:12.398681Z",
     "start_time": "2025-07-29T06:25:12.392019Z"
    }
   },
   "cell_type": "code",
   "source": [
    "PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "DATA_DIR = os.path.join(PROJECT_ROOT, \"data\")\n",
    "# PROCESSED_CHUNKS_PATH = os.path.join(DATA_DIR, \"pakistan_laws_chunks.csv\")\n",
    "PROCESSED_CHUNKS_PATH = os.path.join(DATA_DIR, \"pakistan_laws_chunks_with_embeddings.csv\")\n",
    "VECTOR_DB_DIR = os.path.join(DATA_DIR, \"chroma_db\") # Directory to store ChromaDB data\n",
    "\n",
    "# Ensure the data directory exists (already should from previous steps)\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "os.makedirs(VECTOR_DB_DIR, exist_ok=True) # Create directory for the vector DB\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n",
    "print(f\"Data directory: {DATA_DIR}\")\n",
    "print(f\"Processed chunks path: {PROCESSED_CHUNKS_PATH}\")\n",
    "print(f\"Vector DB directory: {VECTOR_DB_DIR}\")"
   ],
   "id": "e8632a951e46dda2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /Users/apple/PycharmProjects/LLM_Production_01_RAG/Haq_ooq_RAG\n",
      "Data directory: /Users/apple/PycharmProjects/LLM_Production_01_RAG/Haq_ooq_RAG/data\n",
      "Processed chunks path: /Users/apple/PycharmProjects/LLM_Production_01_RAG/Haq_ooq_RAG/data/pakistan_laws_chunks_with_embeddings.csv\n",
      "Vector DB directory: /Users/apple/PycharmProjects/LLM_Production_01_RAG/Haq_ooq_RAG/data/chroma_db\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T06:28:19.329231Z",
     "start_time": "2025-07-29T06:26:51.657171Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Load the Processed Chunks (now with embeddings) ---\n",
    "try:\n",
    "    chunks_df = pd.read_csv(PROCESSED_CHUNKS_PATH)\n",
    "    # Convert the 'embedding' column from string representation of list to actual list of floats\n",
    "    # This is crucial because Pandas saves lists as strings in CSVs\n",
    "    chunks_df['embedding'] = chunks_df['embedding'].apply(eval) # eval() safely converts string representation of list to list\n",
    "    \n",
    "    print(f\"\\nSuccessfully loaded {len(chunks_df)} chunks from {PROCESSED_CHUNKS_PATH}\")\n",
    "    print(\"\\nFirst 5 chunks:\")\n",
    "    print(chunks_df.head())\n",
    "    print(\"\\nDataFrame columns:\", chunks_df.columns.tolist())\n",
    "    print(\"\\nExample chunk content (first 200 chars):\")\n",
    "    if not chunks_df.empty:\n",
    "        print(chunks_df['chunk_content'].iloc[0][:200])\n",
    "        print(f\"\\nShape of the first embedding: {len(chunks_df['embedding'].iloc[0])}\")\n",
    "    else:\n",
    "        print(\"DataFrame is empty.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: {PROCESSED_CHUNKS_PATH} not found.\")\n",
    "    print(\"Please ensure 'pakistan_laws_chunks_with_embeddings.csv' is in your 'data/' directory.\")\n",
    "    chunks_df = pd.DataFrame() # Initialize an empty DataFrame to prevent further errors\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while loading or processing the CSV: {e}\")\n",
    "    chunks_df = pd.DataFrame()"
   ],
   "id": "91b022cb193cfcb0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully loaded 30122 chunks from /Users/apple/PycharmProjects/LLM_Production_01_RAG/Haq_ooq_RAG/data/pakistan_laws_chunks_with_embeddings.csv\n",
      "\n",
      "First 5 chunks:\n",
      "                                         source_file          section_title  \\\n",
      "0  administrator00532129aba2e10fe634ab8fbd94c50b.pdf  Preamble/Introduction   \n",
      "1  administrator00532129aba2e10fe634ab8fbd94c50b.pdf  Preamble/Introduction   \n",
      "2  administrator00532129aba2e10fe634ab8fbd94c50b.pdf  Preamble/Introduction   \n",
      "3  administrator00532129aba2e10fe634ab8fbd94c50b.pdf  Preamble/Introduction   \n",
      "4  administrator00532129aba2e10fe634ab8fbd94c50b.pdf  Preamble/Introduction   \n",
      "\n",
      "                                       chunk_content  chunk_length  \\\n",
      "0  THE PRIVATISATION COMMISSION ORDINANCE, 2000 P...          1499   \n",
      "1  Annual Report. 38. Information to Public. 39. ...          1498   \n",
      "2  day of October, 1999, and the Provisional Cons...          1495   \n",
      "3  (g) “person” includes an individual, partnersh...          1499   \n",
      "4  Act, 1996, (Act XVII of 1996), the National El...          1493   \n",
      "\n",
      "   start_index_in_section  original_chunk_index  \\\n",
      "0                       0                     0   \n",
      "1                    1353                     1   \n",
      "2                    2706                     2   \n",
      "3                    4055                     3   \n",
      "4                    5414                     4   \n",
      "\n",
      "                                           embedding  \n",
      "0  [-0.020446470007300377, -0.03650873154401779, ...  \n",
      "1  [-0.03825778886675835, -0.047717299312353134, ...  \n",
      "2  [-0.0220494344830513, -0.061562299728393555, 0...  \n",
      "3  [-0.0031373128294944763, -0.02057635597884655,...  \n",
      "4  [-0.019504304975271225, -0.04712844640016556, ...  \n",
      "\n",
      "DataFrame columns: ['source_file', 'section_title', 'chunk_content', 'chunk_length', 'start_index_in_section', 'original_chunk_index', 'embedding']\n",
      "\n",
      "Example chunk content (first 200 chars):\n",
      "THE PRIVATISATION COMMISSION ORDINANCE, 2000 PART I.—GENERAL SECTIONS: 1. Short title, extent and commencement. 2. Definitions. PART II.—PRIVATISATION COMMISSION 3. Establishment of the Commission. 4.\n",
      "\n",
      "Shape of the first embedding: 1024\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T10:48:47.819766Z",
     "start_time": "2025-07-27T10:48:35.596120Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = SentenceTransformer(\"BAAI/bge-large-en-v1.5\")\n",
    "\n",
    "try:\n",
    "    # Set device to 'cuda' if GPU is available, otherwise 'cpu'\n",
    "    model = SentenceTransformer(\"BAAI/bge-large-en-v1.5\", device='cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(\"Embedding model loaded successfully.\")\n",
    "    print(f\"Model will run on: {model.device}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading embedding model: {e}\")\n",
    "    # ... (rest of your fallback logic)"
   ],
   "id": "e355f57f9be2fff8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding model loaded successfully.\n",
      "Model will run on: cpu\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Generate Embeddings",
   "id": "40b0d8ac47f6018e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-07-27T10:49:01.043503Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy\n",
    "print(f\"\\nGenerating embeddings for {len(chunks_df)} chunks...\")\n",
    "tqdm.pandas(desc='Generating embeddings...')\n",
    "\n",
    "chunks_df['embedding'] = chunks_df['chunk_content'].progress_apply(lambda x: model.encode(x).tolist())\n",
    "print(\"\\nEmbeddings generated successfully!\")\n",
    "print(\"\\nDataFrame with embeddings (first chunk's embedding snippet):\")\n"
   ],
   "id": "631f397a34f28206",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating embeddings for 30122 chunks...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings...:   0%|          | 0/30122 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4b17d656499c447387b284ee910c7e04"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/PycharmProjects/LLM_Production_01_RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1520: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T06:28:53.969448Z",
     "start_time": "2025-07-29T06:28:53.754579Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Print a snippet of the first embedding to confirm its presence and type\n",
    "if not chunks_df.empty and 'embedding' in chunks_df.columns:\n",
    "    print(chunks_df[['source_file', 'section_title', 'chunk_content', 'embedding']].head(1))\n",
    "    print(f\"\\nShape of the first embedding: {len(chunks_df['embedding'].iloc[0])}\")\n",
    "else:\n",
    "    print(\"No chunks or embedding column found.\")"
   ],
   "id": "29f9e5b1cd95c5a4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         source_file          section_title  \\\n",
      "0  administrator00532129aba2e10fe634ab8fbd94c50b.pdf  Preamble/Introduction   \n",
      "\n",
      "                                       chunk_content  \\\n",
      "0  THE PRIVATISATION COMMISSION ORDINANCE, 2000 P...   \n",
      "\n",
      "                                           embedding  \n",
      "0  [-0.020446470007300377, -0.03650873154401779, ...  \n",
      "\n",
      "Shape of the first embedding: 1024\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T06:33:11.211189Z",
     "start_time": "2025-07-29T06:33:01.203164Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Initialize ChromaDB Client ---\n",
    "print(f\"\\nInitializing ChromaDB client at: {VECTOR_DB_DIR}\")\n",
    "\n",
    "client = chromadb.PersistentClient(path=VECTOR_DB_DIR)\n",
    "COLLECTION_NAME = \"pakistan_laws_chunks_collection\"\n",
    "EMBEDDING_MODEL_NAME = \"BAAI/bge-large-en-v1.5\"\n",
    "\n",
    "try:\n",
    "    collection = client.get_or_create_collection(COLLECTION_NAME, embedding_function=embedding_functions.SentenceTransformerEmbeddingFunction(model_name=EMBEDDING_MODEL_NAME, device='cpu'))\n",
    "    print(f\"ChromaDB collection '{COLLECTION_NAME}' accessed/created.\")\n",
    "    print(f\"Current count in collection: {collection.count()} chunks.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error accessing/creating ChromaDB collection: {e}\")\n",
    "    print(\"Please ensure ChromaDB is correctly installed and accessible.\")\n",
    "    # Exit or handle error appropriately if collection cannot be created/accessed\n",
    "    exit()"
   ],
   "id": "ebdd68597b9ac152",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initializing ChromaDB client at: /Users/apple/PycharmProjects/LLM_Production_01_RAG/Haq_ooq_RAG/data/chroma_db\n",
      "ChromaDB collection 'pakistan_laws_chunks_collection' accessed/created.\n",
      "Current count in collection: 0 chunks.\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T06:50:25.599098Z",
     "start_time": "2025-07-29T06:50:22.631503Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# prepare data for chroma db\n",
    "ids = [f\"chunk_{i}\" for i in range(len(chunks_df))]\n",
    "documents = chunks_df['chunk_content'].tolist()\n",
    "metadatas = chunks_df[['source_file', 'section_title', 'chunk_length', 'start_index_in_section']].to_dict(orient='records')\n",
    "embeddings = chunks_df['embedding'].tolist()"
   ],
   "id": "ee0dc6b5f434eeb2",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T06:58:00.002651Z",
     "start_time": "2025-07-29T06:54:07.909395Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Add Embeddings to the Collection ---\n",
    "if collection.count() == len(ids):\n",
    "    print(\"All chunks already appear to be in the collection. Skipping add operation.\")\n",
    "else:\n",
    "    print(f\"\\nAdding {len(ids)} chunks to the ChromaDB collection. This might take a moment...\")\n",
    "    BATCH_SIZE = 500\n",
    "    for i in tqdm(range(0, len(ids), BATCH_SIZE), desc=\"Adding chunks to ChromaDB\"):\n",
    "        batch_ids = ids[i:i+BATCH_SIZE]\n",
    "        batch_documents = documents[i:i+BATCH_SIZE]\n",
    "        batch_metadatas = metadatas[i:i+BATCH_SIZE]\n",
    "        batch_embeddings = embeddings[i:i+BATCH_SIZE]\n",
    "        \n",
    "        collection.add(\n",
    "            ids=batch_ids,\n",
    "            documents=batch_documents,\n",
    "            metadatas=batch_metadatas,\n",
    "            embeddings=batch_embeddings\n",
    "        )\n",
    "        print(\"\\nAll chunks successfully added to ChromaDB!\")\n",
    "        \n",
    "print(f\"\\nFinal count in ChromaDB collection '{COLLECTION_NAME}': {collection.count()} chunks.\")\n",
    "print(\"\\n--- Task 3: Embedding Generation and Vector Database Indexing complete! ---\")"
   ],
   "id": "52085d48006192e0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Adding 30122 chunks to the ChromaDB collection. This might take a moment...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Adding chunks to ChromaDB:   0%|          | 0/61 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e703abe0770f4ea3b917501bb9305c3d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All chunks successfully added to ChromaDB!\n",
      "\n",
      "All chunks successfully added to ChromaDB!\n",
      "\n",
      "All chunks successfully added to ChromaDB!\n",
      "\n",
      "All chunks successfully added to ChromaDB!\n",
      "\n",
      "All chunks successfully added to ChromaDB!\n",
      "\n",
      "All chunks successfully added to ChromaDB!\n",
      "\n",
      "All chunks successfully added to ChromaDB!\n",
      "\n",
      "All chunks successfully added to ChromaDB!\n",
      "\n",
      "All chunks successfully added to ChromaDB!\n",
      "\n",
      "All chunks successfully added to ChromaDB!\n",
      "\n",
      "All chunks successfully added to ChromaDB!\n",
      "\n",
      "All chunks successfully added to ChromaDB!\n",
      "\n",
      "All chunks successfully added to ChromaDB!\n",
      "\n",
      "All chunks successfully added to ChromaDB!\n",
      "\n",
      "All chunks successfully added to ChromaDB!\n",
      "\n",
      "All chunks successfully added to ChromaDB!\n",
      "\n",
      "All chunks successfully added to ChromaDB!\n",
      "\n",
      "All chunks successfully added to ChromaDB!\n",
      "\n",
      "All chunks successfully added to ChromaDB!\n",
      "\n",
      "All chunks successfully added to ChromaDB!\n",
      "\n",
      "All chunks successfully added to ChromaDB!\n",
      "\n",
      "All chunks successfully added to ChromaDB!\n",
      "\n",
      "All chunks successfully added to ChromaDB!\n",
      "\n",
      "All chunks successfully added to ChromaDB!\n",
      "\n",
      "All chunks successfully added to ChromaDB!\n",
      "\n",
      "All chunks successfully added to ChromaDB!\n",
      "\n",
      "All chunks successfully added to ChromaDB!\n",
      "\n",
      "All chunks successfully added to ChromaDB!\n",
      "\n",
      "All chunks successfully added to ChromaDB!\n",
      "\n",
      "All chunks successfully added to ChromaDB!\n",
      "\n",
      "All chunks successfully added to ChromaDB!\n",
      "\n",
      "All chunks successfully added to ChromaDB!\n",
      "\n",
      "All chunks successfully added to ChromaDB!\n",
      "\n",
      "All chunks successfully added to ChromaDB!\n",
      "\n",
      "All chunks successfully added to ChromaDB!\n",
      "\n",
      "All chunks successfully added to ChromaDB!\n",
      "\n",
      "All chunks successfully added to ChromaDB!\n",
      "\n",
      "All chunks successfully added to ChromaDB!\n",
      "\n",
      "All chunks successfully added to ChromaDB!\n",
      "\n",
      "All chunks successfully added to ChromaDB!\n",
      "\n",
      "All chunks successfully added to ChromaDB!\n",
      "\n",
      "All chunks successfully added to ChromaDB!\n",
      "\n",
      "All chunks successfully added to ChromaDB!\n",
      "\n",
      "All chunks successfully added to ChromaDB!\n",
      "\n",
      "All chunks successfully added to ChromaDB!\n",
      "\n",
      "All chunks successfully added to ChromaDB!\n",
      "\n",
      "All chunks successfully added to ChromaDB!\n",
      "\n",
      "All chunks successfully added to ChromaDB!\n",
      "\n",
      "All chunks successfully added to ChromaDB!\n",
      "\n",
      "All chunks successfully added to ChromaDB!\n",
      "\n",
      "All chunks successfully added to ChromaDB!\n",
      "\n",
      "All chunks successfully added to ChromaDB!\n",
      "\n",
      "All chunks successfully added to ChromaDB!\n",
      "\n",
      "All chunks successfully added to ChromaDB!\n",
      "\n",
      "All chunks successfully added to ChromaDB!\n",
      "\n",
      "All chunks successfully added to ChromaDB!\n",
      "\n",
      "All chunks successfully added to ChromaDB!\n",
      "\n",
      "All chunks successfully added to ChromaDB!\n",
      "\n",
      "All chunks successfully added to ChromaDB!\n",
      "\n",
      "All chunks successfully added to ChromaDB!\n",
      "\n",
      "All chunks successfully added to ChromaDB!\n",
      "\n",
      "Final count in ChromaDB collection 'pakistan_laws_chunks_collection': 30122 chunks.\n",
      "\n",
      "--- Task 3: Embedding Generation and Vector Database Indexing complete! ---\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "446e3af316a829d0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
